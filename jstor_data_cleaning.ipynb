{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning jstor papers\n",
    "\n",
    "def jstor_cleaner(dir,limit):\n",
    "    from bs4 import BeautifulSoup\n",
    "    import nltk.corpus  \n",
    "    from nltk import word_tokenize\n",
    "    import re\n",
    "    import os\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    import enchant\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) - {'at'}\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    stop=0\n",
    "    counter=0\n",
    "    duplicate=[]\n",
    "    fail=[]\n",
    "\n",
    "    for root,dirs,files, in os.walk(dir):\n",
    "        for file in files:\n",
    "            stop+=1\n",
    "            if stop == limit:\n",
    "                break\n",
    "            path_to_txt = os.path.join(root, file)\n",
    "            [stem, ext] = os.path.splitext(path_to_txt)\n",
    "            elif '_cleaned' in file:\n",
    "                # saves the already cleaned file\n",
    "                duplicate.append(file.replace('_cleaned',''))\n",
    "                continue\n",
    "            elif file in str(duplicate):\n",
    "                # checks whether the file is cleaned\n",
    "                print('duplicate', counter)\n",
    "                counter+=1\n",
    "                continue \n",
    "            elif ext == '.txt' and '_cleaned' not in file:\n",
    "                try:\n",
    "                    txt_file = open(stem+ext,'r',encoding=\"utf8\")\n",
    "                    paper=txt_file.read()\n",
    "                    soup = BeautifulSoup(paper, \"html\")\n",
    "                    paper_token=word_tokenize(re.sub(r'\\d+', '',soup.getText().lower().translate(str.maketrans('','', string.punctuation))))\n",
    "\n",
    "                    paper_stop = [w for w in paper_token if not w in stop_words]\n",
    "                    paper_clean=[word for word in paper_stop if word.isalpha() and len(word)>1 and d.check(word) == True]\n",
    "\n",
    "                    counter+=1\n",
    "                    path_to_cleaned=stem+'_cleaned'+ext\n",
    "\n",
    "                    with open(path_to_cleaned, 'w',encoding=\"utf-8\") as cleaned:\n",
    "                        print('paper #',counter)\n",
    "                        cleaned.write(str(paper_clean))\n",
    "                except:\n",
    "                    fail.append(file)\n",
    "                    counter+=1\n",
    "                    continue"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}