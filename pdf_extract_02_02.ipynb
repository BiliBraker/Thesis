{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/pdfs/10.1136_bmjopen-2018-028767/txts/.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-32d43371a743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mextract_text_from_pdfs_recursively\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/pdfs/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-32d43371a743>\u001b[0m in \u001b[0;36mextract_text_from_pdfs_recursively\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mpdf_contents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_pdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mpath_to_txt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstem\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/txts/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtxt_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                     \u001b[1;31m#print(\"Writing contents to \" + path_to_txt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/pdfs/10.1136_bmjopen-2018-028767/txts/.txt'"
     ]
    }
   ],
   "source": [
    "# works like charm\n",
    "# converts .pdf files in selected directory to .txt files\n",
    "\n",
    "from tika import parser\n",
    "import os\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file \n",
    "\n",
    "def extract_text_from_pdfs_recursively(dir):\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            path_to_pdf = os.path.join(root, file)\n",
    "            [stem, ext] = os.path.splitext(path_to_pdf)\n",
    "            #s_words = set(stopwords.words('english'))\n",
    "            #print(s_words)\n",
    "            if ext == '.pdf':\n",
    "                #print(\"Processing \" + path_to_pdf)\n",
    "                pdf_contents = parser.from_file(path_to_pdf)\n",
    "                \n",
    "                # problem: saves the txts to the same directory\n",
    "                \n",
    "                path_to_txt = stem + '.txt'\n",
    "                with open(path_to_txt, 'w') as txt_file:\n",
    "                    #print(\"Writing contents to \" + path_to_txt)\n",
    "                    \n",
    "                    # a bit ugly...\n",
    "                    \n",
    "                    pdf_contents = str(pdf_contents['content'].encode('utf-8', errors='ignore')).replace(\"\\n\", \"\").replace(\"\\\\\", \"\").lower()\n",
    "                    pdf_contents = re.sub(\"(\\\\d|\\\\W)+\",\" \",pdf_contents)\n",
    "                    \n",
    "                    \n",
    "                    #pdf_contents = word_tokenize(pdf_contents)\n",
    "                    #pdf_contents = [x for x in pdf_contents if x not in s_words]\n",
    "                    \n",
    "                    txt_file.write(str(pdf_contents))\n",
    "                    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_text_from_pdfs_recursively(\"c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/pdfs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7900"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searching for keywords\n",
    "# ~working\n",
    "\n",
    "# https://stackoverflow.com/questions/47649987/how-to-save-nltk-concordance-results-in-a-list\n",
    "\n",
    "def concordance(ci, word, width=75, lines=100):\n",
    "    \"\"\"\n",
    "    Rewrite of nltk.text.ConcordanceIndex.print_concordance that returns results\n",
    "    instead of printing them. \n",
    "\n",
    "    See:\n",
    "    http://www.nltk.org/api/nltk.html#nltk.text.ConcordanceIndex.print_concordance\n",
    "    \"\"\"\n",
    "    half_width = (width - len(word) - 2) // 2\n",
    "    context = width // 4 # approx number of words of context\n",
    "\n",
    "    results = []\n",
    "    offsets = ci.offsets(word)\n",
    "    if offsets:\n",
    "        lines = min(lines, len(offsets))\n",
    "        for i in offsets:\n",
    "            if lines <= 0:\n",
    "                break\n",
    "            left = (' ' * half_width +\n",
    "                    ' '.join(ci._tokens[i-context:i]))\n",
    "            right = ' '.join(ci._tokens[i+1:i+context])\n",
    "            left = left[-half_width:]\n",
    "            right = right[:half_width]\n",
    "            results.append('%s %s %s' % (left, ci._tokens[i], right))\n",
    "            lines -= 1\n",
    "\n",
    "    return results\n",
    "\n",
    "# https://stackoverflow.com/questions/29110950/python-concordance-command-in-nltk\n",
    "# http://www.nltk.org/book/ch03.html\n",
    "\n",
    "import nltk.corpus  \n",
    "from nltk import word_tokenize\n",
    "from nltk.text import Text  \n",
    "from nltk import ConcordanceIndex\n",
    "\n",
    "path = 'c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/txts/'\n",
    "\n",
    "# searching for 'missing' in one paper\n",
    "\n",
    "paper = open(path+'Briggs-2003-Missing-presumed-at-random-cost-ana.txt','rb')\n",
    "\n",
    "paper_token = word_tokenize(str(paper.read()))\n",
    "\n",
    "paper_txt = Text(paper_token)\n",
    "\n",
    "\n",
    "\n",
    "# occurence of 'missing' in the text\n",
    "\n",
    "ci = ConcordanceIndex(paper_txt.tokens)\n",
    "\n",
    "paper_conc = str(concordance(ci,'missing'))\n",
    "\n",
    "paper_conc\n",
    "\n",
    "#len(paper_txt.concordance_list('missing')) # gives only the length of the displayed results\n",
    "\n",
    "#len(ConcordanceIndex(paper_txt.tokens).offsets('missing')) # gives the correct number of results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>missing</th>\n",
       "      <th>impute</th>\n",
       "      <th>imputing</th>\n",
       "      <th>imputation</th>\n",
       "      <th>imputed</th>\n",
       "      <th>pairwise</th>\n",
       "      <th>listwise</th>\n",
       "      <th>deletion</th>\n",
       "      <th>delete</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.1136_bmjopen-2018-028767.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.1371_journal.pcbi.1007399.txt</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Banbura-2014-Maximum-likelihood-estimation-of-...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Briggs-2003-Missing-presumed-at-random-cost-an...</td>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Bunji-Okada2019_Article_ItemResponseAndRespons...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>clinical stuff - tresiba and ryzodeg evaluatio...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Deng-2016-Multiple-imputation-for-general-mis.txt</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Donald B. Rubin - Multiple Imputation for Nonr...</td>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>dudbrigde-likelihood-based association analysi...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Gareth James, Daniela Witten, Trevor Hastie, R...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>generalized robust ratio estimator for imputat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ichikawa et al- handling mising data in a ffq.txt</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Implementing Multiple Ratio Imputation by the ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>imputation of the 1989 survey of consumer fina...</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>karahalios et al-handling missing data in coho...</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>mice_package.txt</td>\n",
       "      <td>296</td>\n",
       "      <td>533</td>\n",
       "      <td>7</td>\n",
       "      <td>290</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Mirkes-2016-Handling-missing-data-in-large-hea...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Multiple Ratio Imputation by the EMB Algorithm...</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>multiple-imputation-for-statistical-disclosure...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Ngaruye2018_Article_Small-areaEstimationWithMi...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>papers.csv</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Roderick J. A. Little, Donald B. Rubin - Stati...</td>\n",
       "      <td>1056</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>266</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>rubin-meng-likelihood raito test with imputed ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>sentences.csv</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>takahashi et al- imputing the mean of a hetero...</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>takahashi multiple imputation.txt</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>takahashi- MI of missing values in economic su...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>takahashi- MI of turnover in edinet data.txt</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>takahiro-junichiro-missing_data_bank_of_japan.txt</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>tanaka et al- missing data clinical trials.txt</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>thering et al-identifying missing data mechani...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>tomita et al- a bias-corrected estimator in mu...</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>variance estimation with hot deck imputation.txt</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>zhuang et al- detection and replenishment of m...</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  missing  impute  \\\n",
       "0                     10.1136_bmjopen-2018-028767.txt        3       0   \n",
       "1                    10.1371_journal.pcbi.1007399.txt       88      12   \n",
       "2   Banbura-2014-Maximum-likelihood-estimation-of-...       78       0   \n",
       "3   Briggs-2003-Missing-presumed-at-random-cost-an...      134       2   \n",
       "4   Bunji-Okada2019_Article_ItemResponseAndRespons...        1       0   \n",
       "5   clinical stuff - tresiba and ryzodeg evaluatio...       20       3   \n",
       "6   Deng-2016-Multiple-imputation-for-general-mis.txt       60       7   \n",
       "7   Donald B. Rubin - Multiple Imputation for Nonr...      284      40   \n",
       "8   dudbrigde-likelihood-based association analysi...       40       0   \n",
       "9   Gareth James, Daniela Witten, Trevor Hastie, R...       14       0   \n",
       "10  generalized robust ratio estimator for imputat...        0       0   \n",
       "11  ichikawa et al- handling mising data in a ffq.txt      102       2   \n",
       "12  Implementing Multiple Ratio Imputation by the ...        9       0   \n",
       "13  imputation of the 1989 survey of consumer fina...       53      13   \n",
       "14  karahalios et al-handling missing data in coho...      112       1   \n",
       "15                                   mice_package.txt      296     533   \n",
       "16  Mirkes-2016-Handling-missing-data-in-large-hea...       21       1   \n",
       "17  Multiple Ratio Imputation by the EMB Algorithm...       89       0   \n",
       "18  multiple-imputation-for-statistical-disclosure...        0       0   \n",
       "19  Ngaruye2018_Article_Small-areaEstimationWithMi...       23       0   \n",
       "20                                         papers.csv        8       1   \n",
       "21  Roderick J. A. Little, Donald B. Rubin - Stati...     1056      21   \n",
       "22  rubin-meng-likelihood raito test with imputed ...       20       0   \n",
       "23                                      sentences.csv        8       1   \n",
       "24  takahashi et al- imputing the mean of a hetero...       35       3   \n",
       "25                  takahashi multiple imputation.txt       14       0   \n",
       "26  takahashi- MI of missing values in economic su...       36       1   \n",
       "27       takahashi- MI of turnover in edinet data.txt       50       3   \n",
       "28  takahiro-junichiro-missing_data_bank_of_japan.txt       75       6   \n",
       "29     tanaka et al- missing data clinical trials.txt       79       1   \n",
       "30  thering et al-identifying missing data mechani...       67       0   \n",
       "31  tomita et al- a bias-corrected estimator in mu...       60       4   \n",
       "32   variance estimation with hot deck imputation.txt       26       0   \n",
       "33  zhuang et al- detection and replenishment of m...       77       0   \n",
       "\n",
       "    imputing  imputation  imputed  pairwise  listwise  deletion  delete  \\\n",
       "0          0           0        0         0         0         0       0   \n",
       "1          2          37        9         0         0         0       0   \n",
       "2          0           0        0         0         0         0       0   \n",
       "3          6          61       19         0         1         3       0   \n",
       "4          0           0        0         0         0         0       0   \n",
       "5          0           7        6         0         0         0       0   \n",
       "6          4          62       15         0         0         0       0   \n",
       "7         10         465      142         1         0         0       0   \n",
       "8          0           2        0         0         0         0       0   \n",
       "9          0           0        0         8         0         0       1   \n",
       "10         0           0        0         0         0         0       0   \n",
       "11         2          66        8         0         0         1       0   \n",
       "12         0          58       22         0         0         0       0   \n",
       "13         0          83       28         0         0         0       1   \n",
       "14         1          24        2         0         0         0       0   \n",
       "15         7         290      155         0         1         1       0   \n",
       "16         1          10        0         0         0         0       4   \n",
       "17         2         215       20         0        18        18       0   \n",
       "18         0           0        0         0         0         0       0   \n",
       "19         0           0        0         0         0         0       0   \n",
       "20         2           3        2         1         1         1       1   \n",
       "21        34         266      103         1         0         1       3   \n",
       "22         0          18       13         0         0         0       0   \n",
       "23         2           3        2         1         1         1       1   \n",
       "24        15          37        1         0         2         1       0   \n",
       "25         0          41        2         0         4         2       0   \n",
       "26         1          48       10         0         0         0       0   \n",
       "27         0         108       43         0         0         1       0   \n",
       "28         0         178       12         0         0         0       0   \n",
       "29         0          18        0         0         0         0       0   \n",
       "30         0           6        0         1         0         4       0   \n",
       "31         1         113       21         0         0         0       0   \n",
       "32         1         114       22         0         0         0       4   \n",
       "33         0           2        2         0         0         0       0   \n",
       "\n",
       "    deleted  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  \n",
       "15        1  \n",
       "16        2  \n",
       "17        0  \n",
       "18        0  \n",
       "19        0  \n",
       "20        0  \n",
       "21        6  \n",
       "22        0  \n",
       "23        0  \n",
       "24        0  \n",
       "25        0  \n",
       "26        2  \n",
       "27        0  \n",
       "28        0  \n",
       "29        0  \n",
       "30        0  \n",
       "31        0  \n",
       "32        0  \n",
       "33        1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe \n",
    "# works fine\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk.corpus  \n",
    "from nltk import word_tokenize\n",
    "from nltk.text import Text  \n",
    "from nltk import ConcordanceIndex\n",
    "\n",
    "\n",
    "path = \"c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/txts/\"\n",
    "filelist = os.listdir(path)\n",
    "filelist_sort = filelist[0:5]\n",
    "sentences_list = []\n",
    "papers_list = []\n",
    "keywords = [\"missing\",\"impute\",\"imputing\",\"imputation\",\"imputed\",\"pairwise\",\"listwise\",\"deletion\",\"delete\",\"deleted\"]\n",
    "\n",
    "papers = pd.DataFrame(filelist)\n",
    "sentences_df = pd.DataFrame(filelist)\n",
    "values_list = []\n",
    "\n",
    "for j in range(len(keywords)):\n",
    "    for i in range(len(filelist)):\n",
    "    #print(filelist[i])\n",
    "        paper = open(path+filelist[i],'rb')\n",
    "\n",
    "        paper_token = word_tokenize(str(paper.read()))\n",
    "\n",
    "        paper_txt = Text(paper_token)\n",
    "        \n",
    "        ci = ConcordanceIndex(paper_txt.tokens)\n",
    "\n",
    "        sentences = str(concordance(ci,keywords[j]))\n",
    "    \n",
    "        value = len(ConcordanceIndex(paper_txt.tokens).offsets(keywords[j]))\n",
    "        #print(keywords[j],':',value)\n",
    "        \n",
    "        og_dict = {keywords[j]:value}\n",
    "        values_list.append(value)\n",
    "        sentences_list.append(sentences)\n",
    "    \n",
    "    papers = pd.concat([papers.reset_index(drop=True), pd.DataFrame(values_list, columns = [keywords[j]])], axis=1)\n",
    "    sentences_df = pd.concat([sentences_df.reset_index(drop=True), pd.DataFrame(sentences_list, columns = [keywords[j]])], axis=1)\n",
    "    \n",
    "    \n",
    "    values_list = []\n",
    "    sentences_list = []\n",
    "\n",
    "#papers.columns = ['paper',\"missing\",\"impute\",\"imputing\",\"imputation\",\"imputed\",\"pairwise\",\"listwise\",\"deletion\",\"delete\",\"deleted\"]\n",
    "\n",
    "papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers.to_csv(path +'papers.csv')\n",
    "sentences_df.to_csv(path +'sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'missing': 3},\n",
       " {'missing': 88},\n",
       " {'missing': 78},\n",
       " {'missing': 134},\n",
       " {'missing': 1},\n",
       " {'impute': 0},\n",
       " {'impute': 12},\n",
       " {'impute': 0},\n",
       " {'impute': 2},\n",
       " {'impute': 0},\n",
       " {'imputing': 0},\n",
       " {'imputing': 2},\n",
       " {'imputing': 0},\n",
       " {'imputing': 6},\n",
       " {'imputing': 0},\n",
       " {'imputation': 0},\n",
       " {'imputation': 37},\n",
       " {'imputation': 0},\n",
       " {'imputation': 61},\n",
       " {'imputation': 0},\n",
       " {'imputed': 0},\n",
       " {'imputed': 9},\n",
       " {'imputed': 0},\n",
       " {'imputed': 19},\n",
       " {'imputed': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'pairwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 0},\n",
       " {'listwise': 1},\n",
       " {'listwise': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 0},\n",
       " {'deletion': 3},\n",
       " {'deletion': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'delete': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0},\n",
       " {'deleted': 0}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_dict\n",
    "\n",
    "og_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "\n",
    "class my_dictionary(dict): \n",
    "  \n",
    "    # __init__ function \n",
    "    def __init__(self): \n",
    "        self = dict() \n",
    "          \n",
    "    # Function to add key:value \n",
    "    def add(self, key, value): \n",
    "        self[key] = value \n",
    "        \n",
    "dict_obj = my_dictionary() \n",
    "  \n",
    "dict_obj.add(1, 'Geeks') \n",
    "dict_obj.add(2, 'forGeeks') \n",
    "  \n",
    "print(dict_obj) \n",
    "        \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
