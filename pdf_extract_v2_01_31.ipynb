{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# works like charm\n",
    "# converts .pdf files in selected directory to .txt files\n",
    "\n",
    "from tika import parser\n",
    "import os\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# https://stackoverflow.com/questions/34837707/how-to-extract-text-from-a-pdf-file \n",
    "\n",
    "def extract_text_from_pdfs_recursively(dir):\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            path_to_pdf = os.path.join(root, file)\n",
    "            [stem, ext] = os.path.splitext(path_to_pdf)\n",
    "            s_words = set(stopwords.words('english'))\n",
    "            #print(s_words)\n",
    "            if ext == '.pdf':\n",
    "                #print(\"Processing \" + path_to_pdf)\n",
    "                pdf_contents = parser.from_file(path_to_pdf)\n",
    "                path_to_txt = stem + '.txt'\n",
    "                with open(path_to_txt, 'w') as txt_file:\n",
    "                    #print(\"Writing contents to \" + path_to_txt)\n",
    "                    \n",
    "                    # a bit ugly...\n",
    "                    \n",
    "                    pdf_contents = str(pdf_contents['content'].encode('utf-8', errors='ignore')).replace(\"\\n\", \"\").replace(\"\\\\\", \"\").lower()\n",
    "                    pdf_contents = re.sub(\"(\\\\d|\\\\W)+\",\" \",pdf_contents)\n",
    "                    \n",
    "                    \n",
    "                    #pdf_contents = word_tokenize(pdf_contents)\n",
    "                    #pdf_contents = [x for x in pdf_contents if x not in s_words]\n",
    "                    \n",
    "                    txt_file.write(str(pdf_contents))\n",
    "                    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_text_from_pdfs_recursively(\"c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/pdfs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 88 matches:\n",
      "onnnapproaches that aim to estimate missing regulatory signals have been applie\n",
      "on or other strategies for handling missing data we further show that our appro\n",
      "our approachnncan accurately impute missing data after genome segmentation reve\n",
      " currentnnapproaches deal with this missing data problem by either limiting gen\n",
      " analyzed or by predicting what the missing regulatory signals wouldnnhave look\n",
      "s where some regulatory signals are missing nnideas can still provide accurate \n",
      "a current solution is to impute the missing chromatin marks before segmenta nnt\n",
      "larly concerning when the number of missing marks is large as is the common cas\n",
      " errors our method can still impute missing data sets as an end product i e aft\n",
      "een cellnntypes nnresultsnnhandling missing data in the ideas frameworknnwe pre\n",
      "mponent we there nnfore address the missing data problem in the density functio\n",
      " very quickly we first identify all missing data configurations in all cellnnty\n",
      "tion is a standard em algorithm for missing data problems it enables ideas tonn\n",
      "aph to create data collections with missing data we randomly selected some cell\n",
      "ments the remaining cell types with missing data by usingnnthe first segmentati\n",
      "tion by using chromimpute to impute missing data nndirect segmentation but with\n",
      "g journal pcbi nnnas shown in fig a missing data indeed reduces the accuracy fo\n",
      "omatinnnstates as expected the more missing marks or more cell types with missi\n",
      "ssing marks or more cell types with missing marks the lessnnsimilar segmentatio\n",
      "ed by the number of cell types with missing marks and the number of missing mar\n",
      "ith missing marks and the number of missing marks in each cell type results are\n",
      "her separated by cell types without missing marks solid boxes and cell types wi\n",
      "rks solid boxes and cell types with missing marks dashed boxes green dashed lin\n",
      "ta particularly when there are more missing marks innnthe data as an empirical \n",
      "en there are fewernncell types with missing data the segmentations for cell typ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searching for keywords\n",
    "# ~working\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/29110950/python-concordance-command-in-nltk\n",
    "# http://www.nltk.org/book/ch03.html\n",
    "\n",
    "import nltk.corpus  \n",
    "from nltk import word_tokenize\n",
    "from nltk.text import Text  \n",
    "from nltk import ConcordanceIndex\n",
    "\n",
    "path = 'c:/Users/soirk/Krisztian/Egyetem/Survey Statisztika Msc/Szakdolgozat/pdfs/'\n",
    "\n",
    "# searching for 'missing' in one paper\n",
    "\n",
    "paper = open(path+'10.1371_journal.pcbi.1007399.txt','rb')\n",
    "\n",
    "paper_token = word_tokenize(str(paper.read()))\n",
    "\n",
    "paper_txt = Text(paper_token)\n",
    "\n",
    "# occurence of 'missing' in the text\n",
    "\n",
    "paper_txt.concordance('missing')\n",
    "#len(paper_txt.concordance_list('missing')) # gives only the length of the displayed results\n",
    "\n",
    "len(ConcordanceIndex(paper_txt.tokens).offsets('missing')) # gives the correct number of results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
